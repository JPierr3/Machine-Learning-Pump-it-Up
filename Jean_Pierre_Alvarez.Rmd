---
title: "PumpIt"
author: "Jean Pierre Alvarez"
date: "11/28/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T,results = "hide", warning=FALSE, message=F)
```

# Trabajo Final

El siguiente trabajo seguirá la siguiente metodología:

1. Descripción de los datos
2. Depuración y codificación, estandarización y creación de dummies
3. Estudio de selección de variables; selección primaria del mejor set bajo logística
4. Tuneo-optimización comentado de cada algoritmo con el mejor set de variables obtenido anteriormente 
5. Ensamblado.
6. Conclusiones

## 1. Descripción de los datos
Origuen de los datos : 

> [link](https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/data/) 

Una breve descripción de las columnas que contiene el data set:


 
Variable | Descripcion
------------- | -------------
date_recorded | Fecha que la fila fue ingresada 
funder | Organización que fundó el punto de agua 
gps_height | Altura del pozo
installer | Organización que instaló el punto de agua
longitude | GPS
latitude | GPS
wpt_name | Nombre del punto de agua (si es que hubiera uno) 
basin | Localización Geografica (Cuenca)
subvillage | Localización Geografica (subaldea)
region | Localización Geografica ( region)
region_code | Localización Geografica (codigo region)
district_code | Localización Geografica (codigo districto)
lga | Localización Geografica
ward | Localización Geografica (Nombre del Barrio)
population | Población al rededor del pozo
public_meeting | True/False
recorded_by | Organizacion que ingreso esta información
scheme_management | Quien opera el punto de agua
scheme_name | Quien opera el punto de agua 
permit | Si el punto de agua está permitido o no 
construction_year | Año de construccion del punto de agua 
extraction_type | Tipo de extracción de agua que el punto de agua utiliza 
extraction_type_group | Grupo de extracción de agua que el punto de agua utiliza 
extraction_type_class | Clase de extracción de agua que el punto de agua utiliza 
management | Como se administra el punto de agua 
management_group | Grupo como se administra el punto de agua 
payment | Lo que costó el agúa 
payment_type | Lo que costó el agúa 
water_quality | Calidad del agua  
quality_group | Grupo Calidad del agua  
quantity | Cantidad de agua
quantity_group | Grupo de Cantidad de agua
source | Grupo Calidad del agua  
quality_group | Fuente del agua
source_type | Tipo de la fuente de agua
source_class |  Clase de la fuente de agua
quality_group | Grupo Calidad del agua  
waterpoint_type | Tipo del punto de agua
waterpoint_type_group | Grupo tipo del punto de agua


### 1.1 Cargamos los Datos

```{r analysis, results="markup"}
# Por optimizacion usamos datatable
library(data.table)

# El siguiente archivo se utilizara para Train/Validation
dTrain       <- as.data.frame(fread("Assets/TrainingSetValues.csv", nThread = 2))
dTrain_label <- as.data.frame(fread("Assets/TrainingSetLabels.csv", nThread = 2))

# Y este archivo se usará para realizar las predicciones del concurso
dTest        <- fread( file = 'Assets/TestSetValues.csv', nThread = 2) 
dTest_label  <- fread( file = 'Assets/Predicciones/SubmissionFormat_original.csv', nThread = 2)  #

dim(dTrain) # obs:59400    var: 40
head(dTrain[1:5,1:5])
```

### 1.2 Exploración de datos
Proporción de valores de la variable objetivo:

Tipo | %
------------- | -------------
functional | 54.30%
functional needs repair | 7.27%
non functional | 38.42%

Con la función summary() ya se empiezan a observar algunos valores "raros" en los datos, como **gps_height** con un valor min. -90 y **amount_tsh** que su media es 317.7 pero tiene un max. 350000, de igual forma **population** tiene valor min. de 0 y max. 30500 de habitantes que viven al rededor del pozo y una media 179.9, lo cual puede haber outliers poco representativos.

```{r}
prop.table(table(dTrain_label$status_group)) * 100
# revisamos las clases asignadas a las variables
str(dTrain)
# revisión rapida de los datos
summary(dTrain)

```
Cuento el número de valores únicos diferentes para las numéricas:

```{r , results="markup"}
sapply(Filter(is.numeric, dTrain),function(x) length(unique(x))) 
```
Observamos que hay valores númericos que podrían ser considerados categoricas como **construction_year**, **region_code**, **district_code**, pero por el momento se quedarán como numéricas hasta que se realice más analisis

```{r grafico para valorar, fig.height = 4, fig.width = 4, fig.align = "center", echo=FALSE}
# Observamos que tiene valores outliers
boxplot(dTrain$population , main="population") 

# Talvez se podría recategorizar los outliers en un solo conjunto
boxplot(dTrain$amount_tsh, main="amount_tsh") 
```
Observamos que las dos variables presentan presentan distribucion asimetrica hacia la izquierda lo que revela presencia de valores minoritarios en la parte derecha que pueden ser considerados como outliers, igual es extraño que en la variable **population** existan tantas personas viviendo alrededor de un pozo 350000 considerando que la media es de 179 habitantes, se podría considerar como missing pero se perdería datos, lo cual preferiblemente se podria convertir a factor recategorizando las variables.

Sobre la variable **amount_tsh** cantidad de agua podría tener sentido si a altura del pozo también es proporcional.
En resumen, los datos revelan la presencia de errores en tipos de variables, valores fuera de rango, missing no declarados, variables potencialmente nominales con categorías poco representadas

Continuamos con la inspeccion de datos con la librería inspectdf
```{r eda ,fig.keep = "none"}
library(inspectdf) 

# categorical plot
# se observan que hay muchas variables desproporcionales en el dataset
x <- inspect_cat(dTrain) 
show_plot(x)

# correlations in numeric columns
# Observamos variables muy correlacionadas, como district_code-region_code y construction_year-gps_height
x <- inspect_cor(dTrain)
show_plot(x)

# feature imbalance bar plot
# muchas variables despropocionadas como: recorded_by, management_group, public_meeting, water_quality, quality_group
x <- inspect_imb(dTrain)
show_plot(x)

# memory usage barplot
# se observa que las variables wpt_name y subvillage son las mas pesadas con 2.85 MB y 1.57 MB respectivamente
x <- inspect_mem(dTrain)
show_plot(x)

# missingness barplot
x <- inspect_na(dTrain)
show_plot(x)

# histograms for numeric columns
# se observa que la variable gps_height esta muy desproporcionada en cantidad
# de igual forma construction_year hay muchos obs en el año 0, asi mismo population que hay varios puntos de agua con 0 habitantes
x <- inspect_num(dTrain)
show_plot(x)

# barplot of column types
x <- inspect_types(dTrain)
show_plot(x)


```
Analizamos valores unicos de las variables cualitativas
```{r }
sapply(Filter(is.character, dTrain),function(x) length(unique(x))) 
```
Las variables que coinciden por poco:

Variable | Valores Unicos | Comentario
------------- | ------------- | -------------
subvillage | 19288 | Exceso de niveles
wpt_name | 37400 | Exceso de niveles
payment | 7 | 
payment_type | 7 | Posible var. duplicadas
recorded_by | 1 | Unico valor
water_quality | 8 | 
quality_group | 6 | Posible var. duplicadas
quantity | 5 | 
quantity_group | 5 | Posible var. duplicadas
source | 10 | 
source_type | 7 | Posible var. duplicadas
waterpoint_type | 7 | 
waterpoint_type_group | 7 | Posible var. duplicadas

### 1.3 Limpieza de datos

Convertimos los character,logical a factor, los int a num e idate a date:
```{r}
dTrain[,sapply(dTrain, is.character)] <- lapply(dTrain[,sapply(dTrain, is.character)], as.factor)
dTrain[,sapply(dTrain, is.logical)]   <- lapply(dTrain[,sapply(dTrain,is.logical)], as.factor)
dTrain$date_recorded                  <- as.Date(dTrain$date_recorded)
dTrain[,sapply(dTrain, is.integer)]   <- lapply(dTrain[,sapply(dTrain,is.integer)], as.numeric)
```

Realizamos la distribución de las variables numericas:

```{r, results="markup"}

psych::describe(Filter(is.numeric, dTrain)) 
```
Se confirma presencia de outliers en **gps_height** y **population** ya que la media y la media presentan diferencias considerables, y aun queda entender porque existen valores negativos en gps_height, pero por  falta de información se escoge no modificar esa variable.

Analizamos los posibles valores duplicados:

```{r duplicados}
library(dplyr)           # Manipulation
# se observa que region_code y region no tienen una relacion de 1 a 1 y una region puede tener distintos region_code
dTrain %>% group_by(region_code,region) %>% count() %>% arrange(desc(region))  

#se observa que la relacion es de 1 a 1, por lo que son columnas duplicadas; se confirma missing no declarados
dTrain %>% group_by(payment, payment_type) %>% count() %>% arrange(desc(payment))  

#  tal vez no sea necesario conservar water_quality porque son variables poco representativas por separado
dTrain %>% group_by(water_quality,quality_group) %>% count() %>% arrange(desc(water_quality)) 

# al ser identicas, eliminamos quantity_group
dTrain %>% group_by(quantity,quantity_group) %>% count() %>% arrange(desc(quantity))  

# son muy parecidas, y podriamos quedarnos con source_type para una segunda iteracion
dTrain %>% group_by(source,source_type) %>% count() %>% arrange(desc(source))  

# nos quedamos con waterpoint_type excluir waterpoint_type_group
dTrain %>% group_by(waterpoint_type,waterpoint_type_group) %>% count() %>% arrange(desc(waterpoint_type))  
table(dTrain$waterpoint_type_group, dTrain_label$status_group)

#se puede limpiar esta variable ya que estan mal escritos algunos nombres o hay espacios demás
#dTrain %>% group_by(fe_installer) %>% count() %>% arrange() # 2146   transformando se obtiene 1882 valoes unicos
#trim <- function (x) gsub("^\\s+|\\s+$", "", x)
#dataT$fe_installer <- toupper(str_replace_all(string=dataT$installer, pattern=" ", repl="") )

dTrain %>% group_by(quantity) %>% count() %>% arrange(desc(n))
table(dTrain$quantity, dTrain_label$status_group)

#dTrain %>% group_by(funder,installer) %>% count() %>% arrange(desc(funder))  
table(dTrain$population, dTrain_label$status_group)
#  p      functional     functional needs repair       non functional
#  0          11274                    1775           8332

```
Hasta el momento lo que se ha encontrado en la data:

Variable | Comentario
------------- | -------------
funder | Palabras mal escritas, espacios en blanco, missing no declarados y niveles de frecuencia bajos en algunos
funder&Installer | suelen coincidir la relacion 1 a 1 excepto por algunos valores
scheme_name | presenta espacios en blanco, NA's 28166 47.4%
population | Tiene valores 0, lo cual es raro ver puntos de agua y no una población que viva al rededor en tanzania 
permit y public_meeting | Tiene NA's 
payment y payment_type | Valores duplicados 
water_quality y quality_group | Valores duplicados excepto por algunos casos 
quantity y quantity_group | Valores duplicados 
source y source_type | Valores muy parecidos 
population | Valores 0, y la gran mayoria tiene puntos de agua funcionales lo cual confirma que son missing no declarados
subvillage | presenta espacios en blanco, NA's 371 0.6%


```{r, results="markup"}
# Revisamos la proporcion de missings de cada variable
head(questionr::freq(dTrain$scheme_management, sort = "dec") )
```
Adicional La mayoria de puntos de agua se encuentran funcionales y tan solo un 7.3% necesitan reparacion, el 38.4% no se encuentran operativos

* functional - 32259 - 54.3%
* functional needs repair - 4317 - 7.3%
* non functional - 22824 - 38.4%

## 2 Depuración y codificación, estandarización y creación de dummies

### 2.1 Tratamiento de missings no declarados
Recodificamos los missings, para una segunda iteración es podria considerar convertir a NA's las variables que tienen "unknown" en sus niveles
```{r}
library(questionr)
# Creamos una nueva variable para tratar la informacion
data <- dTrain
data$scheme_management<-recode.na(data$scheme_management,'')
data$scheme_management<-recode.na(data$scheme_management,'None')
data$subvillage       <-recode.na(data$subvillage,'')
data$funder           <-recode.na(data$funder,0)
data$funder           <-recode.na(data$funder,'0')
data$installer        <-recode.na(data$installer,0)
data$installer        <-recode.na(data$installer,'0')
data$construction_year<-recode.na(data$construction_year,0)
data$construction_year<-recode.na(data$construction_year,'0')

#revisamos que existen 20709 que son NA's y l resto esta entre 1000-2000 obs
data %>% group_by(construction_year) %>% count() %>% arrange(desc(n))
data %>% group_by(population) %>% count() %>% arrange(desc(n))
```

### 2.2 Feature Engineering

Creamos nuevas variables según la fecha que se ingreso el punto de agua, una varaible calculada entre latitude y longitude
creamos la varibale **fe_construction_year** ya que estaba muy desproporcionado en missings
```{r fe}
library(lubridate) 
save(data,file="Assets/Dataset Clean/1_CleanData.Rda")
#Creamos un nuevo df para guaradar las etiquetas
data_label                 <- dTrain_label
data_label$status_group    <- car::recode(data_label$status_group
                                       , "'functional'=2 ;'functional needs repair'=1; 'non functional'=0")
data$fe_anio               <- year(data$date_recorded)
data$fe_mes                <- month(data$date_recorded)
data$fe_dianum             <- day(data$date_recorded)
data$fe_lonlat             <- sqrt(data$longitude^2 + data$latitude^2)
#para indicar si tiene o no año de construccion
data$fe_construction_year  <- as.factor(ifelse(is.na(data$construction_year), FALSE, TRUE) )

head(data)

```
Ahora, revisamos lo que se hará con los missing, si se eliminan o imputan.
De lo encontrado anteriormente se observa que son pocas las observaciones con NA's,  bien podría eliminar pero para no perder información se decide imputar de manera aleatoria para que no haya favoritimos por moda y una variable este desbalanceada.
Antes de imputar separamos los dataset en variable objetivo y los predictores y adicional quitamos de la lista las variables duplicadas o que no aportaran información.
* variable  payment   :duplicada
* variable  quality_group  :duplicada
* variable  quantity_group :duplicada
* variable  source_type    :duplicada
* variable  waterpoint_type_group :duplicada
* variable  date_recorded  :se crearon los fe*
* variable  construction_year  :se crearon los fe*
* variable  longitude  :se crearon los fe*
* variable  latitude  :se crearon los fe*
* variable  recorded_by  :tiene solo un valor
```{r ,fig.keep = "none", results="markup"}
library(psych)
source("Assets/Funciones/Funciones_R.R")
excluir <- c("payment", "quality_group", "quantity_group", "source_type", "waterpoint_type_group", "date_recorded", "construction_year", "longitude","latitude" ,"recorded_by")
clean_data <- data[ , -which(names(data) %in% excluir)] 
save(clean_data,file="Assets/Dataset Clean/2_CleanData.Rda")

# no es observa gran cantidad de missing por lo cual podemos proceder aimputar 
x <- inspect_cat(clean_data) 
show_plot(x)

# observamos que son pocos los valores atipicos en % asi que no es necesario convertir a missing los atipicos
sapply(Filter(is.numeric, clean_data),function(x) atipicosAmissing(x)[[2]])/nrow(clean_data) 


```

### 2.3 Imputamos 
Imputo todas las cualitativas para no perder información ya que observamos que son poco representativas la parte missing, seleccionar el tipo de imputación: moda o aleatorio para no depender de la moda
```{r}
clean_data[,as.vector(which(sapply(clean_data, class)=="factor"))]<-sapply(Filter(is.factor, clean_data),function(x) ImputacionCuali(x,"aleatorio"))
#convertimos a factor, ya que se convirtieron a chr
clean_data[,as.vector(which(sapply(clean_data, class)=="character"))] <- lapply(clean_data[,as.vector(which(sapply(clean_data, class)=="character"))] , factor)
# convertimos las variable fe_dianum integer a num
clean_data$fe_dianum  <- as.numeric(clean_data$fe_dianum)
```



## 3) Estudio de selección de variables; selección primaria del mejor set bajo logística
## 4) Tuneo-optimización comentado de cada algoritmo con el mejor set de variables obtenido anteriormente 
## 6) Ensamblado.
## 7) Conclusiones
